{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios\n",
    "1.-Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL.\n",
    "    a).-Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programación estén en mayúsculas.\n",
    "    b).-Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programación estén en minúsculas.\n",
    "    c).-Cree un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R.\n",
    "2.-Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30].\n",
    "    a).-Cree el RDD llamado sqrt, este debe contener la raíz cuadrada de los elementos que componen el RDD pares.\n",
    "    b).-Obtenga una lista compuesta por los números pares en el intervalo [20;30] y sus respectivas raíces cuadradas. Un ejemplo del resultado deseado para el intervalo [50;60] sería la lista [50, 7.0710678118654755, 52, 7.211102550927978, 54, 7.3484692283495345, 56, 7.483314773547883, 58, 7.615773105863909, 60, 7.745966692414834].\n",
    "    c).-Eleve el número de particiones del RDD sqrt a 20.\n",
    "    d).-Si tuviera que disminuir el número de particiones luego de haberlo establecido en 20, ¿qué función utilizaría para hacer más eficiente su código?\n",
    "3.-Cree un RDD del tipo clave valor a partir de los datos adjuntos como recurso a esta lección. Tenga en cuenta que deberá procesar el RDD leído para obtener el resultado solicitado. Supongamos que el RDD resultante de tipo clave valor refleja las transacciones realizadas por número de cuentas. Obtenga el monto total por cada cuenta.\n",
    "**Tip: Cree su propia función para procesar el RDD leído.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#punto 1\n",
    "rdd = sc.parallelize(['Python', 'R', 'C', 'Scala', 'Rugby','SQL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PYTHON', 'R', 'C', 'SCALA', 'RUGBY', 'SQL']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto a)\n",
    "rdd_mayus = rdd.map(lambda x: x.upper())\n",
    "rdd_mayus.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'r', 'c', 'scala', 'rugby', 'sql']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto b)\n",
    "rdd_minus = rdd.map(lambda x: x.lower())\n",
    "rdd_minus.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 'Rugby']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto c\n",
    "rdd_r = rdd.filter(lambda x: x.startswith('R'))\n",
    "rdd_r.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 22, 24, 26, 28, 30]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto 2\n",
    "rdd_pares = sc.parallelize(range(20,31,2))\n",
    "rdd_pares.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.47213595499958,\n",
       " 4.69041575982343,\n",
       " 4.898979485566356,\n",
       " 5.0990195135927845,\n",
       " 5.291502622129181,\n",
       " 5.477225575051661]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "import math\n",
    "rdd_raiz = rdd_pares.map(lambda x: math.sqrt(x))\n",
    "rdd_raiz.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 4.47213595499958, 22, 4.69041575982343, 24, 4.898979485566356, 26, 5.0990195135927845, 28, 5.291502622129181, 30, 5.477225575051661]\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "import math\n",
    "rdd_compuesto = sc.parallelize(range(20,31,2))\n",
    "rdd_raiz2 = rdd_compuesto.flatMap(lambda x: (x,math.sqrt(x))).collect()\n",
    "print(rdd_raiz2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "rdd_partition = rdd_raiz2.repartition(20)\n",
    "rdd_partition.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d)\n",
    "rdd_coalesce = rdd_partition.coalesce(10)\n",
    "rdd_coalesce.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1001, 52.3)',\n",
       " '(1005, 20.8)',\n",
       " '(1001, 10.1)',\n",
       " '(1004, 52.7)',\n",
       " '(1005, 20.7)',\n",
       " '(1002, 85.3)',\n",
       " '(1004, 20.9)']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "rdd_texto = sc.textFile('./proceso.txt/')\n",
    "rdd_texto.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 1001', ' 52.3 '),\n",
       " (' 1005', ' 20.8 '),\n",
       " (' 1001', ' 10.1 '),\n",
       " (' 1004', ' 52.7 '),\n",
       " (' 1005', ' 20.7 '),\n",
       " (' 1002', ' 85.3 '),\n",
       " (' 1004', ' 20.9 ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def proceso(archivo):\n",
    "    return (tuple(archivo.replace('(',' ').replace(')',' ').split(',')))\n",
    "\n",
    "rdd_llave_valor = rdd_texto.map(proceso)\n",
    "rdd_llave_valor.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 1005', 41.5), (' 1004', 73.6), (' 1001', 62.4), (' 1002', ' 85.3 ')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_llave_valor.reduceByKey(lambda x,y: float(x) + float(y)).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d0711819d275f50fdf21fccbe0c6db757647d13ff622ffbd8a20209bb10ddb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
